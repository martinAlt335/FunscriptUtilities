# Global config
# Either 'extract_frames' or 'extrapolate_frames'.
ACTION_SELECT: extrapolate_frames
# Use CPU or GPU. GPU must be NVIDIA and follow this tutorial: https://github.com/dmlc/decord#install-via-pip. Default: cpu
VIDEO_DECODER: cpu

# Extract frames config
# Saved image width in pixels. Default: 1200px
WIDTH: 1200
# Drop redundant actions (when no change happens between two points in the funscript file). Default: true
REMOVE_DUPLICATES: TRUE
# Should overwrite images from prior runs? * Currently not working fully. Default: FALSE
OVERWRITE: FALSE
# If VR video is detected the saved output is split in half, if you would like to save the image as is this is a bypass. Default: TRUE
FORCE_SAVE: TRUE


# Extrapolate frames config
# Note: For an average 30-45 min VR video there will be a few thousand actions. I found ranging between 1 to 10% very sufficient.
# Eg: A video I tested that had ~8000 actions and the USE_PERCENTAGE at 20% became ~23000 actions.
USE_PERCENTAGE: 5

